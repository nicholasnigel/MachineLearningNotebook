{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Overview\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML the is the science of programming computers to learn from *__data__*.  \n",
    "One example of this application would be _Spam Filtering_. You have a bunch of emails that have been flagged as spam, then let the program learn from the training data. Later on after building the model (fromt training) use it as prediction model to determine whether incoming email is a spam or not.  \n",
    "\n",
    "From the newly predicted emails, we can get a score like _accuracy_ to see whether the model is good enough or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning vs. Rule Making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fundamentally there are two ways on thinking about how to decide whether an email is a spam or not.  \n",
    "\n",
    "1. __Pattern Detection Algorithm__ \n",
    "\n",
    "  We usually see a certain pattern in the fields. Say like the email sender usually contains some random number '001230120' or perhaps the content of the email looks like 'FREE ....'  \n",
    "\n",
    "  We create algorithm to recognize these patterns then and keep finding some patterns.  \n",
    "The disadvantage of this method is that, you will have a long list of complex rules ( using if-else condition everywhere)  \n",
    "\n",
    "\n",
    "2.  __Machine Learning Algorithm__\n",
    "\n",
    "  The Machine Learning Algorithm learns from the existing data immediately and record some patterns directly from the data itself. As a  result, Machine Learning Algorithms are self-adapting.  \n",
    "  \n",
    "  When the spam sender try to avoid using the same pattern and change it, the algorithm will try to recognize it again and see any similarities. So we don't need to put any extra code/rules to counter-act it.  \n",
    "  \n",
    " \n",
    "__Advantages of ML Algorithm is solving:__\n",
    "\n",
    "* Problems without any existing algorithm\n",
    "* Complex Problems without any solutions\n",
    "* Adapting to fluctuating environments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/001_1.jpg\" width=\"500px\" height=\"100px\">  \n",
    "\n",
    "_Fig 1.1 The General Cycle of Machine Learning Algorithm_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data that is being fed to the program must be _labelled_.  \n",
    "\n",
    "Two frequent tasks with supervised learning is classification and regression. Classification puts different instances into respective classes. Regression on the other hand predicts a certain numerical value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just the opposite of supervised learning, the training data is unlabeled. Some applications are: clustering, Dimensionality reduction, Association rule learning.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semisupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithms that deal with partially labelled training data ( lots of unlabeled and little labeled data). It is the combination of supervised and unsupervised.  \n",
    "\n",
    "Example application can be found in Google Photos. We may apply unsupervised learning into the photos to find similar people from each photo. Then if we give labels to only some of these photos and not all, the google photos itself later on will be able to recognize the people. So in here, you don't need to label too many photos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Learning System (agent) can observe the environement, select and perform actions, and get _rewards_. But then the agent must learn by itself what would be the best strategy(policy) in order to get the most/best rewards. Policy then defines what an agent should choose when it is in a given situation.  \n",
    "\n",
    "<img src=\"img/001_2.jpg\" width=\"500px\" height=\"100px\">  \n",
    "\n",
    "_Fig 1.2 Reinforcement Learning_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch and Online Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whether system learns incrementally from incoming data or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Learning\n",
    "\n",
    "System incapable of learning incrementally, and therefore must be first trained with all available data. It is done offline and usually takes a lot of time.  \n",
    "\n",
    "Once the system is done training and launched for project, the system will not, and it will apply whatever it has learned. This is why it's referred to as offline learning.  \n",
    "\n",
    "Another way to add more training is simply add the incoming data to training set and retrain everything from one again. This however will take a lot of time since you have to keep adding new data and redo training again.  \n",
    "\n",
    "Disadvantage of this system if the system need to learn autonomously because it only has a few training sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Online Learning\n",
    "\n",
    "Train system by feeding data instances sequentially (individually or by mini-batches). Learning step is fast and cheap so system can learn about new data on the fly.  \n",
    "\n",
    "It is a good option when the system is continuously fed with flows of data and need to adapt to change rapidly. Also, since it learns data 1 by 1, and once it is learned, we can remove the data. This may save space hugely if we have very limited computing resources.\n",
    "\n",
    "Learning Rate: Parameter to look to about how fast should system change or adapt to incoming data. High learning rate, system learns quickly, but at the same time will quickly forget old data. Conversely, if low learning rate, the machine learns slowly and usually unrepsonsive or less sensitive to noise or sequences of nonrepresentative data points.  \n",
    "\n",
    "Another problem with online learning: if bad data is fed to the system, the system's performance will gradually decline. To handle this, then people need to take care of the incoming data and monitor if there are any anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance-Based vs Model-Based\n",
    "\n",
    "How do systems generalize? Good performance on training data is good but what is important is the result on test data.\n",
    "\n",
    "#### Instance-Based Learning\n",
    "\n",
    "Example: spam filter to be programmed to also flag emails from a known similar email that is already labelled spam. Basically what it does is, group things that are similar by parameter/features together (something like clustering).  \n",
    "\n",
    "#### Model-Based Learning\n",
    "\n",
    "Building model from example of training data, then use the model later on to make prediction. One of the examples would be Linear Regression for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges of Machine Learning  \n",
    "\n",
    "#### Quantity of Training Data\n",
    "\n",
    "It takes a lot of data for a system to understand something through machine learning to make accurate predictions. There is however debate that it really depends on algorithm. Highly efficient algorithms is said to require just small amount of data.  \n",
    "\n",
    "#### Nonrepresentative Training Data\n",
    "\n",
    "Data gathered from the public must be representative/general to all. Example is, if we take rice consumption and only gather in Asia, this will not be representative of what it would be when the same method of data gathering is done in other regions. If we have too little of data, there will be sampling noise. If too much data but method is flawed, there will be sampling bias.\n",
    "\n",
    "#### Poor Quality Data\n",
    "\n",
    "If training data is full of errors or outliers and anomalies, the system will have difficulty in detecting any particular patterns and therefore less likely for system to perform well. To prevent this, data should be cleaned  before being used in an algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Irrelevant Features\n",
    "\n",
    "System will only be capable of learning if the training data contains enough relevant features and not too many irrelevant ones.  \n",
    "\n",
    "Feature Engineering involves:  \n",
    "* Feature Selection: Selecting most useful features to train on among existing features.\n",
    "* Features Extraction: Combine existing features and produce more useful ones. \n",
    "* Create new features by gathering new data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overfitting Training Data\n",
    "\n",
    "Just like humans where we like to over generalize something from just a few data, machine also have that tendency. This overgeneralization is called overfitting, which means that a model does very well in training set, however not so accurate in the testing set.  \n",
    "\n",
    "If training set is noisy, or too small, model is likely to detect patterns in the noise itself. A machine may take an unimportant feature into account and see its trend even though it's going to be irrelevant later on.  One of the examples would be \"Name\".  \n",
    "\n",
    "To solve the overfitting problem we may:  \n",
    "* Select model with fewer parameters (linear model > high-degree polynomial model)\n",
    "* Gather more training data\n",
    "* Reducing noise from training data ( data clean up )  \n",
    "\n",
    "The method of constraining a model to make it simpler and reduce the risk of overfitting is called regularization. What we want to do with regularization is that we want to find the right balance between fitting the data perfectly and keeping the model simple enough to ensure that it will generalize well.  \n",
    "\n",
    "Amount of regularization can be controlled by _hyperparameter_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Underfitting the Training Data  \n",
    "\n",
    "Just the opposite of overfitting, when model is too simple to learn the underlying structure of the data. \n",
    "\n",
    "To fix this problem:\n",
    "* Select more powerful model with more parameters\n",
    "* Feeding better features to learning algorithm ( Feature engineering ) \n",
    "* Reduce constraints on the model. ( reduce regularization hyperparameter )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Validating\n",
    "\n",
    "To know how well a model generalizes we should try it out on new cases.  \n",
    "Best strategy would be to split our existing data into training and testing sets. Train our model in the training sets and test it in the testing sets. The result of error rate on new cases is called the generalization error.  \n",
    "\n",
    "IF training error is low but the testing error is high, means that our model overfits the training data. We can compare how they generalize by using the test set.  \n",
    "\n",
    "There is another problem with regards to setting hyperparameter through regularization. A common solution would be that we have another holdout set that is called the _validation set_.  So we train models with various hyper parameters using the training set, select the model and hyperparameters that perform best on validation set, and when you're happy with the model you run on a single final test against the test set to get estimate of the generalization error.  \n",
    "\n",
    "To avoid wasting training data on validation sets, we use _cross validation_. cross-validation: the training set is split into complementary subsets, and each model is trained against a different combination of these subsets and validated against the remaining parts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
