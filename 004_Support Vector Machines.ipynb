{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines  \n",
    "\n",
    "SVM is capable of performing linear or nonlinear classificatio, regression and even outlier detection. It is suitable for classification of the complex and small-medium size of dataset.\n",
    "\n",
    "Topics:  \n",
    "1. [Linear SVM Classification](#linear_svm_classification)\n",
    "2. [Non-Linear SVM Classification](#nonlinear_svm)\n",
    "3. [SVM Regression](#svm_regression)\n",
    "4. [Analysis on SVM](#analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='linear_svm_classification'>Linear SVM Classification</a>\n",
    "\n",
    "<img src='img/004_1.jpg' width=600px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If 2 classes are linearly separable, the 2 classes can be separated by a straight line. On the picture on the left plot, the dashed line does not even separate the 2 classes. However, the remaining 2 is separating. If we look closely, the 2 lines (decision boundary) seem to be very tight/close to the instances. If we decide to use this, the model will perform badly on new instances.  \n",
    "\n",
    "On the right plot, the solid line is the decision boundary of an SVM classifier. It not only separates the 2 classes, it also is separated quite far away from the training instances. It leaves wide spaces in between the line and the rest of training instances. This is called _large margin classification_.  \n",
    "\n",
    "On another note, SVM is also sensitive to feature scaling. Decision boundary would much look better when the features are scaled, i.e. using StandardScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft Margin Classification\n",
    "\n",
    "_Hard Margin Classification_ is when the line divide the 2 classes stictly and the instances are divided exactly. Problem with hard margin classification is that data has to be linearly separable and that is is sensitive to outliers.  \n",
    "\n",
    "<img src='img/004_2.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the left plot, we see that one class is mixed up with the other class. Now it becomes linearly inseparable. On the right plot, we see thatthe outlier causes the line to be different from the image before. Because of this, later on the model may be proven to be inefficient in predicting new instances.  \n",
    "\n",
    "To avoid big errors from hard margin classification, we have the soft margin classification which is a balance of keeping the 'street' as large as possible mean while making as little margin violations as possible. (Margin violations are like the misclassified instances, or outlier where it is within the margins.  \n",
    "\n",
    "For scikit learn, we can control this using C hyperparameter. It will control the tradeoff between wider street and the margin violations. Smaller C means wider street but more margin violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('linear_svc', LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0))])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris['data'][:,(2,3)] # petal length and petal width\n",
    "y = (iris['target']==2).astype(np.float64) # Iris-Virginica or not\n",
    "\n",
    "svm_clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('linear_svc', LinearSVC(C=1, loss='hinge'))\n",
    "])\n",
    "\n",
    "svm_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.predict([[5.5, 1.7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x107a121d0>,\n",
       " <matplotlib.lines.Line2D at 0x118c5f240>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X[y==1], 'r.')\n",
    "plt.plot(X[y==0], 'b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='nonlinear_svm'>Nonlinear SVM Classification</a>\n",
    "\n",
    "Not all datasets are necessarily linearly separable. If dataset is not linearly separable, one method we can use is to add some features from the datasets using existing features (i.e. polynomial features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('poly_features', PolynomialFeatures(degree=3, include_bias=True, interaction_only=False)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm_clf', LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_svm_clf = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures(degree=3)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm_clf', LinearSVC(C=10, loss='hinge'))\n",
    "])\n",
    "\n",
    "poly_svm_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Kernel\n",
    "\n",
    "Eventhough the above implementation uses polynomial features, there might be a disadvantage of usign _PolynomialFeatures_ method. With low degree, it can't deal with complex datasets. With too high of degree, it creates way too many features and affect the model processing time. (Very long time to fit data). \n",
    "\n",
    "There is an alternative of pipelining with PolynomialFeatures, namely the svm implemented polynomial kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm_clf', SVC(C=5, cache_size=200, class_weight=None, coef0=1,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='poly', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.svm import SVC\n",
    "poly_kernel_svm_clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm_clf', SVC(kernel='poly', degree=3, coef0=1, C=5))\n",
    "])\n",
    "poly_kernel_svm_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Features\n",
    "\n",
    "Add features that is computed through similarity function. Similarity function measures how much each instance resembles a particular _landmark_. \n",
    "\n",
    "One of the choice of similarity function is __Gaussian Radial Basis Function__.\n",
    "\n",
    "<img src='img/004_3.jpg'></img>\n",
    "\n",
    "We cacn decide on the $\\gamma$ ourselves to control the shape of curve. For each landmark we decide on, compute it with this equation and that would be the new feature of the data. If we're lucky enough, the data would then become linearly separable (without considering the original feature). \n",
    "\n",
    "Simplest approach to decide on the landmark is that we create landmark at the location of each and every instance in the dataset. But this may create too many dimensions (eventhough the chances of getting linearly separable data is higher). If we have _m_ instances and _n_ features, the transformed data become _m_ instances and _m_ features (after dropping original features). So this approach does not scale well with the number of training instances. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian RBF Kernel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11ace17b8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparing different gamma\n",
    "x = np.linspace(-5,5)\n",
    "y1 = np.exp( -3 * (x-2)**2)\n",
    "y2 = np.exp( -10 * (x-2)**2 )\n",
    "plt.plot(x,y1,label='gamma=3')\n",
    "plt.plot(x,y2, label='gamma=10')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be proven here, that with bigger gamma, the curvature is much smaller.  \n",
    "\n",
    "Polynomial features is computationally expensive and does not scale well with large training sets. The hyperparameter that we can tweak with is the $\\gamma$ and C.  \n",
    "\n",
    "Increasing $\\gamma$ produces narrower curve, instance's range of influence is smaller, and so the decision boundary is more irregular.\n",
    "\n",
    "$\\gamma$ is therefore like a regularization hyperparameter, so we can tweak with it to control when the model is overfitting or underfitting. If model is overfitting, we reduce the $\\gamma$ and the inverse situation also works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='svm_regression'>SVM Regression</a>\n",
    "\n",
    "For earlier SVM classification we try to fit largest possible street in between 2 classes and limit margin violations. SVM regression is the opposite of it, which is to fit as many instances on the street while limiting the margin violations. \n",
    "\n",
    "The width is controlled by hyperparameter $\\epsilon$. Comparing the effect of large and small margin:\n",
    "<img src='img/004_4.jpg'></img>.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVR(C=1.0, dual=True, epsilon=1.5, fit_intercept=True,\n",
       "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "     random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "svm_reg = LinearSVR(epsilon=1.5)\n",
    "svm_reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For non-linear regression, we can use the poly='kernel' method again. To control the margin errors (for regularization) we try different value of C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nigelnicholas/Library/Python/3.6/lib/python/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=100, cache_size=200, coef0=0.0, degree=2, epsilon=0.1,\n",
       "  gamma='auto_deprecated', kernel='poly', max_iter=-1, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_poly_reg = SVR(kernel='poly', degree=2, C=100, epsilon=0.1)\n",
    "svm_poly_reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='analysis'>Analysis on SVM</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is the analysis on what happens under the SVM Classification/Regression.  \n",
    "Notations used:  \n",
    "b : bias term  \n",
    "w : features weight vector\n",
    "\n",
    "Then decision function would look like:  \n",
    "$$\n",
    "\\hat{y} = w^Tx+b\n",
    "$$\n",
    "\n",
    "The decision function then would decide whether the instance is a positive class or negative class. If result of decision function is positive, it would result to positive class as well. \n",
    "\n",
    "<img src='img/004_5.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision boundary would be the set of points whose h function produces to be 0. Decision boundary is the line that is caused by the intersection between the h function and plane.  \n",
    "\n",
    "Then the dashed line represent the h=1 or h=-1. It is of equal distance from the decision boundary and it forms the margin around it.  \n",
    "\n",
    "So objective of the training would be to later on finding the value of w and b making the margin as wide as possible while minimizing margin violations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective of Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing we can observe is that that if divide the slope by 2, it will multiply margin by 2. Smaller the weight vector w, the larger the margin will be.  \n",
    "<img src='img/004_6.jpg'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
